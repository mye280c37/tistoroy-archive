# 인공지능을 보호하는 적대적(Adversarial) AI 기술

> 22.04.27
> 이규영 멘토님

## 적대적 샘플(adversarial sample)

사람 눈에는 제대로 잘못된걸로 보이지 않지만 컴퓨터는 잘못 인식하도록 데이터를 악의적으로 조작한 것

## 공격 종류
 
non targeted attack vs. targeted attack

## GAN

랜덤한 노이즈가 들어오든, 실제 사진과 유사한 데이터가 들어오든 식별자 모델은 식별 결과에 상관없이 항상 정답을 1로 가르친다. 

계속 학습을 하다보면 식별자가 식별결과를 1로 냄

생성자가 식별자를 속일 만큼 우수한 성능을 가지게 됨

<div class="aside">
<div class="title">
‼️ 식별자의 파라미터는 갱신되지 않음 ⇒ 따로 학습 X 
</div>
<div class="contents">
💥 생성자만 학습을 계속함 💥 ⇒ 식별자가 식별결과를 1로 낼 수 있도록 (생성자가 이김)
</div>
</div>

## 관련 프로젝트 주제

### Defense-GAN

새로운 생성 데이터를 통해 GAN을 실시하게 되면 자연스럽게 적대적 예제의 노이즈는 제거되는 효과를 가져오게 됨

적대적 샘플을 만들어서 미리 가능한 공격에 대한 경계를 만들어둠

### 설명가능한 인공지능(XAI)

현재 인공지능은 “Black Box”라 어떻게 돌아가는지 알 수 없다

이와 달리 다른 프로그래밍은 “White Box”라 어떻게 돌아가는지 알기 때문에 그 안의 내용을 이용해 공격이 가능하다.

내부의 로직을 교란시킬 수 있는 “악의적인 입력 구문”을 만들어냄

black box인 인공지능도 마찬가지로 “악의적인 입력 구문”을 만들어내 공격함

인공지능에 대해 설명할 수 있다면 공격에 대한 예측 및 방어가 가능해질 수 있다.

### ART

Tools to develop Adversarial AI

### (*) 시리같은 음성인식 모델의 오류 해결 가능

오류 발생원인: 노이즈가 섞여들어가면서 인식 오류

⇒ 이를 GAN으로 미리 학습시키는 게 가능할듯

### (*) 자율주행학습용 데이터 생성

장애물을 인지하고 하는 것에 대해 GAN을 이용해 학습영상데이터를 더 많이 생성해낼 수 있다.
➡️ 데이터의 가변성을 높임
➕ 변형 데이터 생성을 통해 공격을 방지할 수도 있다.